#!/usr/bin/env python3
"""
AI Agent åç«¯æµ‹è¯•è¿è¡Œå™¨
æä¾›å®Œæ•´çš„æµ‹è¯•åŠŸèƒ½ï¼ŒåŒ…æ‹¬å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•å’Œæ€§èƒ½æµ‹è¯•
"""

import asyncio
import pytest
import sys
import os
import time
import json
import requests
import aiohttp
from pathlib import Path
from typing import Dict, Any, List, Optional
import tempfile
import base64

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.logger import setup_logger, get_logger
from src.config import ConfigManager
from src.mcp import MCPManager
from src.llm import LLMManager
from src.speech import SpeechProcessor

# è®¾ç½®æµ‹è¯•æ—¥å¿—
setup_logger(log_level="DEBUG", log_dir="test_logs", app_name="ai_agent_test")
logger = get_logger(__name__)

class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, server_url: str = "http://localhost:8000"):
        self.server_url = server_url
        self.session = None
        self.test_results = []
    
    async def setup(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        logger.info("ğŸ”§ åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ")
        
        self.session = aiohttp.ClientSession()
        
        # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
        await self.wait_for_server()
        
        logger.info("âœ… æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
    
    async def cleanup(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        logger.info("ğŸ§¹ æ¸…ç†æµ‹è¯•ç¯å¢ƒ")
        
        if self.session:
            await self.session.close()
        
        logger.info("âœ… æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆ")
    
    async def wait_for_server(self, timeout: int = 30):
        """ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨"""
        logger.info("â³ ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨...")
        
        start_time = time.time()
        while time.time() - start_time < timeout:
            try:
                async with self.session.get(f"{self.server_url}/api/health") as response:
                    if response.status == 200:
                        logger.info("âœ… æœåŠ¡å™¨å·²å¯åŠ¨")
                        return
            except:
                pass
            
            await asyncio.sleep(1)
        
        raise TimeoutError("æœåŠ¡å™¨å¯åŠ¨è¶…æ—¶")
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸ§ª å¼€å§‹è¿è¡Œæ‰€æœ‰æµ‹è¯•")
        
        test_suites = [
            ("ç³»ç»Ÿå¥åº·æ£€æŸ¥", self.test_system_health),
            ("MCPé…ç½®ç®¡ç†", self.test_mcp_management),
            ("LLMé…ç½®ç®¡ç†", self.test_llm_management),
            ("è¯­éŸ³è¯†åˆ«åŠŸèƒ½", self.test_speech_recognition),
            ("è¯­éŸ³åˆæˆåŠŸèƒ½", self.test_speech_synthesis),
            ("æ–‡æœ¬å¯¹è¯åŠŸèƒ½", self.test_text_chat),
            ("è¯­éŸ³å¯¹è¯åŠŸèƒ½", self.test_voice_chat),
            ("å¹¶å‘æ€§èƒ½æµ‹è¯•", self.test_concurrent_requests),
            ("é”™è¯¯å¤„ç†æµ‹è¯•", self.test_error_handling)
        ]
        
        total_tests = len(test_suites)
        passed_tests = 0
        
        for i, (test_name, test_func) in enumerate(test_suites, 1):
            logger.info(f"ğŸ” è¿è¡Œæµ‹è¯• [{i}/{total_tests}]: {test_name}")
            
            try:
                start_time = time.time()
                await test_func()
                duration = time.time() - start_time
                
                self.test_results.append({
                    "name": test_name,
                    "status": "PASSED",
                    "duration": duration,
                    "error": None
                })
                
                passed_tests += 1
                logger.info(f"âœ… æµ‹è¯•é€šè¿‡: {test_name} ({duration:.2f}s)")
                
            except Exception as e:
                duration = time.time() - start_time
                
                self.test_results.append({
                    "name": test_name,
                    "status": "FAILED",
                    "duration": duration,
                    "error": str(e)
                })
                
                logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {test_name} - {str(e)}")
        
        # è¾“å‡ºæµ‹è¯•æ€»ç»“
        logger.info(f"ğŸ“Š æµ‹è¯•å®Œæˆ: {passed_tests}/{total_tests} é€šè¿‡")
        
        return self.test_results
    
    async def test_system_health(self):
        """æµ‹è¯•ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
        
        # å¥åº·æ£€æŸ¥
        async with self.session.get(f"{self.server_url}/api/health") as response:
            assert response.status == 200
            data = await response.json()
            assert data["status"] in ["healthy", "degraded"]
        
        # ç³»ç»ŸçŠ¶æ€
        async with self.session.get(f"{self.server_url}/api/status") as response:
            assert response.status == 200
            data = await response.json()
            assert "uptime" in data
            assert "mcp_tools" in data
            assert "llm_models" in data
    
    async def test_mcp_management(self):
        """æµ‹è¯•MCPé…ç½®ç®¡ç†"""
        
        # è·å–MCPé…ç½®åˆ—è¡¨
        async with self.session.get(f"{self.server_url}/api/mcp/configs") as response:
            assert response.status == 200
            configs = await response.json()
            assert isinstance(configs, list)
        
        # åˆ›å»ºæµ‹è¯•MCPé…ç½®
        test_config = {
            "name": "test_mcp_tool",
            "description": "æµ‹è¯•MCPå·¥å…·",
            "command": "python",
            "args": ["test_mcp_server.py"],
            "transport": "stdio"
        }
        
        async with self.session.post(
            f"{self.server_url}/api/mcp/configs",
            json=test_config
        ) as response:
            assert response.status == 200
            created_config = await response.json()
            config_id = created_config["id"]
        
        # æµ‹è¯•MCPé…ç½®
        async with self.session.post(
            f"{self.server_url}/api/mcp/configs/{config_id}/test"
        ) as response:
            assert response.status == 200
        
        # æ›´æ–°MCPé…ç½®
        update_data = {"description": "æ›´æ–°åçš„æµ‹è¯•MCPå·¥å…·"}
        async with self.session.put(
            f"{self.server_url}/api/mcp/configs/{config_id}",
            json=update_data
        ) as response:
            assert response.status == 200
        
        # åˆ é™¤MCPé…ç½®
        async with self.session.delete(
            f"{self.server_url}/api/mcp/configs/{config_id}"
        ) as response:
            assert response.status == 200
    
    async def test_llm_management(self):
        """æµ‹è¯•LLMé…ç½®ç®¡ç†"""
        
        # è·å–LLMé…ç½®åˆ—è¡¨
        async with self.session.get(f"{self.server_url}/api/llm/configs") as response:
            assert response.status == 200
            configs = await response.json()
            assert isinstance(configs, list)
        
        # åˆ›å»ºæµ‹è¯•LLMé…ç½®
        test_config = {
            "name": "test_llm_model",
            "provider": "dashscope",
            "model_name": "qwen-test",
            "api_key": "test_api_key_1234567890",
            "temperature": 0.7
        }
        
        async with self.session.post(
            f"{self.server_url}/api/llm/configs",
            json=test_config
        ) as response:
            assert response.status == 200
            created_config = await response.json()
            config_id = created_config["id"]
        
        # æµ‹è¯•LLMé…ç½®
        async with self.session.post(
            f"{self.server_url}/api/llm/configs/{config_id}/test"
        ) as response:
            assert response.status == 200
        
        # åˆ é™¤LLMé…ç½®
        async with self.session.delete(
            f"{self.server_url}/api/llm/configs/{config_id}"
        ) as response:
            assert response.status == 200
    
    async def test_speech_recognition(self):
        """æµ‹è¯•è¯­éŸ³è¯†åˆ«åŠŸèƒ½"""
        
        # åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ–‡ä»¶
        test_audio_data = self.create_test_audio()
        
        # å‡†å¤‡multipartæ•°æ®
        data = aiohttp.FormData()
        data.add_field(
            'audio_file',
            test_audio_data,
            filename='test.wav',
            content_type='audio/wav'
        )
        data.add_field('language', 'zh-CN')
        
        async with self.session.post(
            f"{self.server_url}/api/speech/recognize",
            data=data
        ) as response:
            assert response.status == 200
            result = await response.json()
            assert "text" in result
            assert "confidence" in result
    
    async def test_speech_synthesis(self):
        """æµ‹è¯•è¯­éŸ³åˆæˆåŠŸèƒ½"""
        
        test_request = {
            "text": "è¿™æ˜¯ä¸€ä¸ªè¯­éŸ³åˆæˆæµ‹è¯•",
            "language": "zh-CN",
            "speed": 1.0,
            "pitch": 1.0
        }
        
        async with self.session.post(
            f"{self.server_url}/api/speech/synthesize",
            json=test_request
        ) as response:
            assert response.status == 200
            result = await response.json()
            assert "audio_data" in result
            assert "format" in result
    
    async def test_text_chat(self):
        """æµ‹è¯•æ–‡æœ¬å¯¹è¯åŠŸèƒ½"""
        
        test_request = {
            "message": "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ¶ˆæ¯",
            "model_name": None,  # ä½¿ç”¨é»˜è®¤æ¨¡å‹
            "session_id": "test_session_123"
        }
        
        async with self.session.post(
            f"{self.server_url}/api/chat/text",
            json=test_request
        ) as response:
            assert response.status == 200
            result = await response.json()
            assert "content" in result
            assert "model_name" in result
            assert "session_id" in result
    
    async def test_voice_chat(self):
        """æµ‹è¯•è¯­éŸ³å¯¹è¯åŠŸèƒ½"""
        
        # åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ–‡ä»¶
        test_audio_data = self.create_test_audio()
        
        # å‡†å¤‡multipartæ•°æ®
        data = aiohttp.FormData()
        data.add_field(
            'audio_file',
            test_audio_data,
            filename='test.wav',
            content_type='audio/wav'
        )
        data.add_field('session_id', 'test_voice_session_123')
        
        async with self.session.post(
            f"{self.server_url}/api/chat/voice",
            data=data
        ) as response:
            assert response.status == 200
            result = await response.json()
            assert "user_text" in result
            assert "response_text" in result
            assert "response_audio" in result
    
    async def test_concurrent_requests(self):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚æ€§èƒ½"""
        
        # å¹¶å‘å¥åº·æ£€æŸ¥
        tasks = []
        for i in range(10):
            task = self.session.get(f"{self.server_url}/api/health")
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks)
        
        for response in responses:
            assert response.status == 200
            response.close()
    
    async def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        
        # æµ‹è¯•ä¸å­˜åœ¨çš„ç«¯ç‚¹
        async with self.session.get(f"{self.server_url}/api/nonexistent") as response:
            assert response.status == 404
            
        # æµ‹è¯•æ— æ•ˆçš„MCPé…ç½®
        invalid_mcp_config = {
            "name": "",  # æ— æ•ˆçš„åç§°
            "command": "invalid_command"
        }
        
        async with self.session.post(
            f"{self.server_url}/api/mcp/configs",
            json=invalid_mcp_config
        ) as response:
            assert response.status == 400
        
        # æµ‹è¯•æ— æ•ˆçš„LLMé…ç½®
        invalid_llm_config = {
            "name": "test",
            "provider": "invalid_provider",
            "model_name": "test"
        }
        
        async with self.session.post(
            f"{self.server_url}/api/llm/configs",
            json=invalid_llm_config
        ) as response:
            assert response.status == 400
    
    def create_test_audio(self) -> bytes:
        """åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ•°æ®"""
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„WAVæ–‡ä»¶å¤´å’Œé™éŸ³æ•°æ®
        import struct
        
        # WAVæ–‡ä»¶å¤´
        sample_rate = 16000
        duration = 1  # 1ç§’
        channels = 1
        bits_per_sample = 16
        
        # è®¡ç®—å‚æ•°
        byte_rate = sample_rate * channels * bits_per_sample // 8
        block_align = channels * bits_per_sample // 8
        data_size = sample_rate * duration * channels * bits_per_sample // 8
        
        # æ„å»ºWAVå¤´
        wav_header = struct.pack('<4sI4s4sIHHIIHH4sI',
            b'RIFF',
            36 + data_size,
            b'WAVE',
            b'fmt ',
            16,  # fmt chunk size
            1,   # PCM format
            channels,
            sample_rate,
            byte_rate,
            block_align,
            bits_per_sample,
            b'data',
            data_size
        )
        
        # åˆ›å»ºé™éŸ³æ•°æ®
        audio_data = b'\x00' * data_size
        
        return wav_header + audio_data
    
    def generate_test_report(self) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report = {
            "timestamp": time.time(),
            "total_tests": len(self.test_results),
            "passed": len([t for t in self.test_results if t["status"] == "PASSED"]),
            "failed": len([t for t in self.test_results if t["status"] == "FAILED"]),
            "total_duration": sum(t["duration"] for t in self.test_results),
            "tests": self.test_results
        }
        
        return json.dumps(report, indent=2, ensure_ascii=False)

class PerformanceTestRunner:
    """æ€§èƒ½æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, server_url: str = "http://localhost:8000"):
        self.server_url = server_url
        self.session = None
    
    async def setup(self):
        """åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•ç¯å¢ƒ"""
        self.session = aiohttp.ClientSession()
    
    async def cleanup(self):
        """æ¸…ç†æ€§èƒ½æµ‹è¯•ç¯å¢ƒ"""
        if self.session:
            await self.session.close()
    
    async def run_load_test(self, concurrent_users: int = 10, requests_per_user: int = 10):
        """è¿è¡Œè´Ÿè½½æµ‹è¯•"""
        logger.info(f"ğŸš€ å¼€å§‹è´Ÿè½½æµ‹è¯•: {concurrent_users} å¹¶å‘ç”¨æˆ·, æ¯ç”¨æˆ· {requests_per_user} è¯·æ±‚")
        
        async def user_simulation(user_id: int):
            """æ¨¡æ‹Ÿå•ä¸ªç”¨æˆ·çš„è¯·æ±‚"""
            user_results = []
            
            for i in range(requests_per_user):
                start_time = time.time()
                try:
                    async with self.session.get(f"{self.server_url}/api/health") as response:
                        duration = time.time() - start_time
                        user_results.append({
                            "user_id": user_id,
                            "request_id": i,
                            "status_code": response.status,
                            "duration": duration,
                            "success": response.status == 200
                        })
                except Exception as e:
                    duration = time.time() - start_time
                    user_results.append({
                        "user_id": user_id,
                        "request_id": i,
                        "status_code": None,
                        "duration": duration,
                        "success": False,
                        "error": str(e)
                    })
            
            return user_results
        
        # å¯åŠ¨å¹¶å‘ç”¨æˆ·
        tasks = [user_simulation(i) for i in range(concurrent_users)]
        all_results = await asyncio.gather(*tasks)
        
        # æ•´ç†ç»“æœ
        flat_results = [result for user_results in all_results for result in user_results]
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        successful_requests = [r for r in flat_results if r["success"]]
        failed_requests = [r for r in flat_results if not r["success"]]
        
        stats = {
            "total_requests": len(flat_results),
            "successful_requests": len(successful_requests),
            "failed_requests": len(failed_requests),
            "success_rate": len(successful_requests) / len(flat_results) * 100,
            "avg_response_time": sum(r["duration"] for r in successful_requests) / len(successful_requests) if successful_requests else 0,
            "min_response_time": min(r["duration"] for r in successful_requests) if successful_requests else 0,
            "max_response_time": max(r["duration"] for r in successful_requests) if successful_requests else 0
        }
        
        logger.info(f"ğŸ“Š è´Ÿè½½æµ‹è¯•å®Œæˆ: æˆåŠŸç‡ {stats['success_rate']:.1f}%, å¹³å‡å“åº”æ—¶é—´ {stats['avg_response_time']:.3f}s")
        
        return stats, flat_results

async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="AI Agent åç«¯æµ‹è¯•è¿è¡Œå™¨")
    parser.add_argument("--server", default="http://localhost:8000", help="æœåŠ¡å™¨åœ°å€")
    parser.add_argument("--test-type", choices=["all", "unit", "integration", "performance"], 
                       default="all", help="æµ‹è¯•ç±»å‹")
    parser.add_argument("--output", help="æµ‹è¯•æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶")
    parser.add_argument("--concurrent-users", type=int, default=10, help="å¹¶å‘ç”¨æˆ·æ•°ï¼ˆæ€§èƒ½æµ‹è¯•ï¼‰")
    parser.add_argument("--requests-per-user", type=int, default=10, help="æ¯ç”¨æˆ·è¯·æ±‚æ•°ï¼ˆæ€§èƒ½æµ‹è¯•ï¼‰")
    
    args = parser.parse_args()
    
    if args.test_type in ["all", "unit", "integration"]:
        # åŠŸèƒ½æµ‹è¯•
        test_runner = TestRunner(args.server)
        
        try:
            await test_runner.setup()
            results = await test_runner.run_all_tests()
            
            # ç”ŸæˆæŠ¥å‘Š
            report = test_runner.generate_test_report()
            
            if args.output:
                with open(args.output, 'w', encoding='utf-8') as f:
                    f.write(report)
                logger.info(f"ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
            else:
                print(report)
        
        finally:
            await test_runner.cleanup()
    
    if args.test_type in ["all", "performance"]:
        # æ€§èƒ½æµ‹è¯•
        perf_runner = PerformanceTestRunner(args.server)
        
        try:
            await perf_runner.setup()
            stats, results = await perf_runner.run_load_test(
                args.concurrent_users, 
                args.requests_per_user
            )
            
            print(json.dumps(stats, indent=2, ensure_ascii=False))
        
        finally:
            await perf_runner.cleanup()

if __name__ == "__main__":
    asyncio.run(main())